{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKER_ID = \"WorkerId\"\n",
    "MTURK_URL = \"https://mturk-uncertainty.s3.amazonaws.com/\"\n",
    "CERTAINTY_COLUMNS = [\"Answer.certainty1\", \"Answer.certainty2\", \"Answer.certainty3\", \"Answer.certainty4\", \"Answer.certainty5\", \"Answer.certainty6\", \"Answer.certainty7\", \"Answer.certainty8\"]\n",
    "VIDEO_URL_COLUMNS = [\"Input.video1_url\", \"Input.video2_url\", \"Input.video3_url\", \"Input.video4_url\", \"Input.video5_url\", \"Input.video6_url\", \"Input.video7_url\", \"Input.video8_url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qualified_annotators = pd.read_csv(\"qualified.csv\")[WORKER_ID]\n",
    "qualified_annotator_list = qualified_annotators.to_list()\n",
    "print(qualified_annotators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = []\n",
    "for batch_filename in [\"batch2_results.csv\", \"batch3_results.csv\", \"batch4_results.csv\", \"batch5_results.csv\"]:\n",
    "    data = pd.read_csv(batch_filename)\n",
    "    useful_data = data[data[WORKER_ID].isin(qualified_annotator_list)]\n",
    "    full_data.append(useful_data)\n",
    "full_data = pd.concat(full_data)\n",
    "print(f\"We have {len(full_data) * 8} data points, we were expecting 6480{', so everything is fine' if len(full_data) * 8 == 6480 else ' there is something wrong!'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_range, upper_range = [], []\n",
    "annotator_low_range, annotator_upper_range = {}, {}\n",
    "annotator_ids = {}\n",
    "\n",
    "for i, annotator in enumerate(qualified_annotator_list):\n",
    "    annotations = full_data[full_data[WORKER_ID] == annotator]\n",
    "\n",
    "    full_annotations = [] \n",
    "    for column in CERTAINTY_COLUMNS:\n",
    "        full_annotations.extend(annotations[column].to_list())\n",
    "\n",
    "    # full_annotations = np.array(full_annotations)\n",
    "    # full_annotations = (full_annotations - np.min(full_annotations)) / (np.max(full_annotations) - np.min(full_annotations)) \n",
    "    annotator_low_range[annotator] = np.min(full_annotations)\n",
    "    annotator_upper_range[annotator] = np.max(full_annotations)\n",
    "\n",
    "    lower_range.append(np.min(full_annotations))\n",
    "    upper_range.append(np.max(full_annotations))\n",
    "    annotator_ids[annotator] = i \n",
    "\n",
    "    # print(f\"{annotator}: {np.min(full_annotations)} - {np.max(full_annotations)} ({np.max(full_annotations)})\")\n",
    "    print(f\"{annotator}: {len(full_annotations)}\")\n",
    "\n",
    "print(np.mean(lower_range), np.mean(upper_range))\n",
    "print(np.median(lower_range), np.median(upper_range))\n",
    "\n",
    "print(annotator_low_range)\n",
    "print(annotator_upper_range)\n",
    "print(len(qualified_annotator_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video_column_name, certainty_column_name in zip(VIDEO_URL_COLUMNS, CERTAINTY_COLUMNS):\n",
    "    for index, row in full_data[[video_column_name, certainty_column_name, WORKER_ID]].iterrows():\n",
    "        video_name = row[video_column_name].replace(MTURK_URL, \"\")\n",
    "        annoator_name = row[WORKER_ID]\n",
    "        with open(os.path.join(\"data\", \"JSON-copy\", video_name.replace('mp4', 'json')), \"r\") as file:\n",
    "            data = json.load(file)\n",
    "            data['annotator'] = row[WORKER_ID]\n",
    "            data['annotator_id'] = annotator_ids[row[WORKER_ID]]\n",
    "            data['confidence'] = row[certainty_column_name]\n",
    "            # data['confidence'] = (row[certainty_column_name] - annotator_low_range[annoator_name]) / (annotator_upper_range[annoator_name] - annotator_low_range[annoator_name])\n",
    "    \n",
    "        with open(os.path.join(\"data\", \"JSON\", video_name.replace('mp4', 'json')), \"w\") as file:\n",
    "            json.dump(data, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
